{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3294ad7-f1d2-47e0-a71e-9ace0672452c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-13 13:43:46.779925: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-13 13:43:46.783167: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-06-13 13:43:46.792163: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749833026.807177  101714 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749833026.811693  101714 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749833026.823499  101714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749833026.823516  101714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749833026.823518  101714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749833026.823519  101714 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-13 13:43:46.827258: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "E0000 00:00:1749833029.307493  101714 cuda_executor.cc:1228] INTERNAL: CUDA Runtime error: Failed call to cudaGetRuntimeVersion: Error loading CUDA libraries. GPU will not be used.: Error loading CUDA libraries. GPU will not be used.\n",
      "W0000 00:00:1749833029.307904  101714 gpu_device.cc:2341] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Processing images:   0%|          | 0/6199 [00:00<?, ?it/s]WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749833035.929722  101714 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n",
      "W0000 00:00:1749833037.564568  101714 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -76 } dim { size: -77 } dim { size: 1024 } } } inputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -23 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3600 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 14 } dim { size: 14 } dim { size: 1024 } } }\n",
      "W0000 00:00:1749833042.579392  101714 op_level_cost_estimator.cc:699] Error in PredictCost() for the op: op: \"CropAndResize\" attr { key: \"T\" value { type: DT_FLOAT } } attr { key: \"extrapolation_value\" value { f: 0 } } attr { key: \"method\" value { s: \"bilinear\" } } inputs { dtype: DT_FLOAT shape { dim { size: -48 } dim { size: -76 } dim { size: -77 } dim { size: 1024 } } } inputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 4 } } } inputs { dtype: DT_INT32 shape { dim { size: -23 } } } inputs { dtype: DT_INT32 shape { dim { size: 2 } } value { dtype: DT_INT32 tensor_shape { dim { size: 2 } } int_val: 14 } } device { type: \"CPU\" vendor: \"GenuineIntel\" model: \"110\" frequency: 3600 num_cores: 8 environment { key: \"cpu_instruction_set\" value: \"AVX SSE, SSE2, SSE3, SSSE3, SSE4.1, SSE4.2\" } environment { key: \"eigen\" value: \"3.4.90\" } l1_cache_size: 32768 l2_cache_size: 262144 l3_cache_size: 8388608 memory_size: 268435456 } outputs { dtype: DT_FLOAT shape { dim { size: -23 } dim { size: 14 } dim { size: 14 } dim { size: 1024 } } }\n",
      "Processing images:   0%|          | 18/6199 [01:42<9:17:33,  5.41s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Caminhos dos modelos\n",
    "FACE_MODEL_PATH = 'flavio/models/weights_face_v1.0.0.pb'\n",
    "PLATE_MODEL_PATH = 'flavio/models/weights_plate_v1.0.0.pb'\n",
    "\n",
    "# Diretórios\n",
    "INPUT_BASE_FOLDER = \"/mnt/cadastro/br/sc/balneario_camboriu/fotos_veiculares/panoramica/PM_BAL_CAMB_20230920__ORIGINAL\"\n",
    "OUTPUT_BASE_FOLDER = \"/mnt/data/flavio\"\n",
    "PROCESSED_LOG = os.path.join(OUTPUT_BASE_FOLDER, 'imagens_processadas.txt')\n",
    "\n",
    "# Parâmetros\n",
    "FACE_THRESHOLD = 0.5\n",
    "PLATE_THRESHOLD = 0.5\n",
    "OBFUSCATION_KERNEL = (251, 251)\n",
    "JPEG_QUALITY = 75\n",
    "IMAGE_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff')\n",
    "\n",
    "def load_frozen_graph(pb_file_path):\n",
    "    if not os.path.exists(pb_file_path):\n",
    "        logging.error(f\"Model file not found: {pb_file_path}\")\n",
    "        raise FileNotFoundError(f\"Model file not found: {pb_file_path}\")\n",
    "    with tf.io.gfile.GFile(pb_file_path, \"rb\") as f:\n",
    "        graph_def = tf.compat.v1.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "    return graph\n",
    "\n",
    "face_graph = load_frozen_graph(FACE_MODEL_PATH)\n",
    "face_sess = tf.compat.v1.Session(graph=face_graph)\n",
    "plate_graph = load_frozen_graph(PLATE_MODEL_PATH)\n",
    "plate_sess = tf.compat.v1.Session(graph=plate_graph)\n",
    "\n",
    "# Tensores\n",
    "face_input_tensor = face_graph.get_tensor_by_name(\"image_tensor:0\")\n",
    "face_boxes_tensor = face_graph.get_tensor_by_name(\"detection_boxes:0\")\n",
    "face_scores_tensor = face_graph.get_tensor_by_name(\"detection_scores:0\")\n",
    "plate_input_tensor = plate_graph.get_tensor_by_name(\"image_tensor:0\")\n",
    "plate_boxes_tensor = plate_graph.get_tensor_by_name(\"detection_boxes:0\")\n",
    "plate_scores_tensor = plate_graph.get_tensor_by_name(\"detection_scores:0\")\n",
    "\n",
    "def detect_objects(sess, input_tensor, boxes_tensor, scores_tensor, image, threshold=0.5):\n",
    "    img_expanded = np.expand_dims(image, axis=0)\n",
    "    boxes, scores = sess.run([boxes_tensor, scores_tensor], feed_dict={input_tensor: img_expanded})\n",
    "    boxes = np.squeeze(boxes)\n",
    "    scores = np.squeeze(scores)\n",
    "    detections = []\n",
    "    h, w, _ = image.shape\n",
    "    for i, score in enumerate(scores):\n",
    "        if score >= threshold:\n",
    "            ymin, xmin, ymax, xmax = boxes[i]\n",
    "            x1 = int(xmin * w)\n",
    "            y1 = int(ymin * h)\n",
    "            x2 = int(xmax * w)\n",
    "            y2 = int(ymax * h)\n",
    "            detections.append((x1, y1, x2, y2, score))\n",
    "    return detections\n",
    "\n",
    "def blur_regions(image, detections, kernel_size=(251, 251)):\n",
    "    processed_image = image.copy()\n",
    "    for (x1, y1, x2, y2, score) in detections:\n",
    "        x1 = max(0, x1)\n",
    "        y1 = max(0, y1)\n",
    "        x2 = min(processed_image.shape[1], x2)\n",
    "        y2 = min(processed_image.shape[0], y2)\n",
    "        if x1 >= x2 or y1 >= y2:\n",
    "            continue\n",
    "        roi = processed_image[y1:y2, x1:x2]\n",
    "        k_h = kernel_size[0] if kernel_size[0] % 2 != 0 else kernel_size[0] + 1\n",
    "        k_w = kernel_size[1] if kernel_size[1] % 2 != 0 else kernel_size[1] + 1\n",
    "        if roi.shape[0] < k_h or roi.shape[1] < k_w:\n",
    "            continue\n",
    "        for _ in range(3):\n",
    "            roi = cv2.GaussianBlur(roi, (k_h, k_w), 0)\n",
    "        processed_image[y1:y2, x1:x2] = roi\n",
    "    return processed_image\n",
    "\n",
    "def non_max_suppression(detections, iou_threshold=0.3):\n",
    "    if not detections:\n",
    "        return []\n",
    "    boxes = []\n",
    "    scores = []\n",
    "    for (x1, y1, x2, y2, score) in detections:\n",
    "        boxes.append([x1, y1, x2 - x1, y2 - y1])\n",
    "        scores.append(score)\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, scores, score_threshold=0.0, nms_threshold=iou_threshold)\n",
    "    if len(indices) > 0:\n",
    "        indices = indices.flatten()\n",
    "        return [detections[i] for i in indices]\n",
    "    return []\n",
    "\n",
    "def process_and_save_image(input_path, output_path):\n",
    "    image = cv2.imread(input_path)\n",
    "    if image is None:\n",
    "        return\n",
    "    face_detections = detect_objects(face_sess, face_input_tensor, face_boxes_tensor, face_scores_tensor, image, FACE_THRESHOLD)\n",
    "    plate_detections = detect_objects(plate_sess, plate_input_tensor, plate_boxes_tensor, plate_scores_tensor, image, PLATE_THRESHOLD)\n",
    "    all_detections = face_detections + plate_detections\n",
    "    filtered = non_max_suppression(all_detections)\n",
    "    final = blur_regions(image, filtered, OBFUSCATION_KERNEL) if filtered else image\n",
    "    cv2.imwrite(output_path, final, [cv2.IMWRITE_JPEG_QUALITY, JPEG_QUALITY])\n",
    "\n",
    "# Criação de pastas\n",
    "if not os.path.exists(OUTPUT_BASE_FOLDER):\n",
    "    os.makedirs(OUTPUT_BASE_FOLDER)\n",
    "\n",
    "# Registro de imagens já processadas\n",
    "imagens_processadas = set()\n",
    "if os.path.exists(PROCESSED_LOG):\n",
    "    with open(PROCESSED_LOG, 'r') as f:\n",
    "        imagens_processadas = set(l.strip() for l in f)\n",
    "\n",
    "files_to_process = []\n",
    "for root, dirs, files in os.walk(INPUT_BASE_FOLDER):\n",
    "    rel_path = os.path.relpath(root, INPUT_BASE_FOLDER)\n",
    "    output_dir = os.path.join(OUTPUT_BASE_FOLDER, rel_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for file in files:\n",
    "        if file.lower().endswith(IMAGE_EXTENSIONS):\n",
    "            input_file_path = os.path.join(root, file)\n",
    "            output_file_path = os.path.join(output_dir, file)\n",
    "            files_to_process.append((file, input_file_path, output_file_path))\n",
    "\n",
    "# Loop principal com salvamento incremental\n",
    "for file_name, input_path, output_path in tqdm(files_to_process, desc=\"Processing images\"):\n",
    "    if file_name in imagens_processadas:\n",
    "        continue\n",
    "    try:\n",
    "        process_and_save_image(input_path, output_path)\n",
    "        with open(PROCESSED_LOG, 'a') as f:\n",
    "            f.write(file_name + '\\n')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Erro ao processar {file_name}: {e}\")\n",
    "\n",
    "# Encerramento de sessões\n",
    "face_sess.close()\n",
    "plate_sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db585c0f-66d4-44f7-80c2-55426411fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "---------------------------------------------------------------------------\n",
    "ModuleNotFoundError                       Traceback (most recent call last)\n",
    "Cell In[1], line 2\n",
    "      1 import os\n",
    "----> 2 import cv2\n",
    "      3 import numpy as np\n",
    "      4 import tensorflow as tf\n",
    "\n",
    "ModuleNotFoundError: No module named 'cv2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbb702-f725-4a5f-b180-4f46811c1b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7763a-dc38-40d3-a238-a0c96c7ca5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless --break-system-packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c07e9-d25e-4048-b553-5ed1c4221366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --user opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a81b4f8-4c5c-4b28-bcfe-782fb9f56f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --break-system-packages opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f665693-7380-4604-a53b-fed779da3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow --break-system-packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350da42-9a68-4a1b-9126-f3a3495c9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b1be9-b066-4bb7-881c-f133bc181356",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm --break-system-packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc812c-203c-43af-b5bd-0deaa508a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source /home/katyperry/pyenv/bin/activate\n",
    "pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5071a43f-37cf-42f3-9702-3c19dd1c8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15902871-23d4-4856-9e2c-823f38824d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f781d-f7ce-43f5-8386-36f7bf053b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anon)",
   "language": "python",
   "name": "anon_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
